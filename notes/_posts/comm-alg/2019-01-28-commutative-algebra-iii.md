---
title: 'Commutative Algebra (III): Finite Modules'
layout: post
date: 2019-01-28 14:06:08 +0800
tag: [commutative algebra]
macros: >-
  "\\rad":"\\operatorname{rad}",
  "\\Hom":"\\operatorname{Hom}",
  "\\End":"\\operatorname{End}",
  "\\Id":"\\operatorname{Id}",
---

Let $A$ be a ring. An __$A$-module__ $M$ is an abelian group equipped with a scalar multiplication $A\times M\to M$, sending $(a,m)$ to $a\cdot m$ (usually written $am$), satisfying associativity:

$$(aa')m=a(a'm),$$

distributivity:

$$a(m+m')=am+am',\quad(a+a')m=am+a'm,$$

and $1m=m$.

If we fix $a\in A$, then scalar multiplication by $a$ gives a map $m\mapsto am$ which is a (group) endomorphism of $M$. Moreover, if we consider the (non-commutative) endomorphism ring $\End(M)$, with addition defined pointwise and multiplication given by composition, then an $A$-module structure on $M$ is equivalent to a ring homomorphism $A\to\End(M)$. This is sometimes called the $A$-module __structure homomorphism__.

This alternative viewpoint is sometimes more convenient. For instance, if $M$ is a $B$-module and $f:A\to B$ is a ring homomorphism, then $M$ gets an $A$-module structure if we define $a\cdot m=f(a)m$. We can verify this fact by explicitly checking all module axioms, or we could simply note that the composition of $f$ with the $B$-module structure homomorphism $B\to\End(M)$ gives a ring homomorphism $A\to\End(M)$, which must then define an $A$-module structure.

## The determinant trick

We say that an $A$-module $M$ is __finite (over $A$)__ if $M$ is finitely generated as an $A$-module. Finite $A$-modules are amenable to the following important "determinant trick," which yields a generalisation of the [Cayley--Hamilton theorem](https://en.wikipedia.org/wiki/Cayley%E2%80%93Hamilton_theorem) in linear algebra:

__Proposition__: Let $M$ be a finite $A$-module generated by $n$ elements, and let $\varphi\in\Hom_A(M,M)$. If $I\subseteq A$ is an ideal such that $\varphi(M)\subseteq IM$, then there exists $a_i\in I^i$ such that

$$\varphi^n+a_1\varphi^{n-1}+\cdots+a_{n-1}\varphi+a_n=0,$$

as endomorphisms of $M$.

__Proof__: Let $M=A\omega_1+\cdots+A\omega_n$. We will first write the condition $\varphi(M)\subseteq IM$ as a "matrix equation": for each $i$, we have

$$\varphi(\omega_i)=\sum_{j=1}^na_{ij}\omega_j$$

for some $a_{ij}\in I$. Moving terms to one side, we get the following for all $i$:

$$\sum_{j=1}^n(\delta_{ij}\varphi-a_{ij}\Id_M)\omega_j=0,$$

where $\delta_{ij}$ is the Kronecker delta, and $\delta_{ij}\varphi-a_{ij}\Id_M$ is interpreted as an endomorphism of $M$.

The next step is to consider the determinant of the matrix $(\delta_{ij}\varphi-a_{ij}\Id_M)_ {i,j}$. As it stands, this is not a well-defined concept, since $\End(M)$ is not necessarily commutative.

However, let us consider the subring $A[\varphi]\subseteq\End(M)$ generated by $A\Id_M$ and $\varphi$; this is the collection of $A$-linear combinations of powers of $\varphi$. Since $A$-multiplication commutes with all endomorphisms of $M$, and powers of $\varphi$ commute, the ring $A[\varphi]$ is in fact commutative, and we can proceed.

The matrix $(\delta_{ij}\varphi-a_{ij}\Id_M)_ {i,j}$ is a matrix with coefficients in $A[\varphi]$, so it has well-defined determinant $d$ and cofactors $b_{ij}$. Multiplying both sides of the matrix equation by the cofactor matrix, we get

$$d\omega_k=0\quad\text{for all }k.$$

Hence $dM=0$ implies $d=0$ as an element of $\End(M)$. Now expanding the determinant $d$ gives us a relation of the desired form. $\qed$

Note that from the appearance of the characteristic polynomial in the proof, we can recover the usual Cayley--Hamilton theorem when $M$ is a free $A$-module and $I=A$.

## Nakayama's lemma

The next result is also commonly attributed to Krull--Azumaya, and is an important result throughout commutative algebra.

__Nakayama's Lemma__: Let $M$ be a finite $A$-module, and let $I\subseteq A$ be an ideal such that $M=IM$. Then there exists $a\in A$ such that $aM=0$ and $a\equiv1\pmod I$.

In particular, if $I\subseteq\rad(A)$ then $M=0$.

__Proof__: Set $\varphi=\Id_M$ in the previous proposition, to get

$$a=1+a_1+\cdots+a_n=0$$

as endomorphisms of $M$, so $aM=0$. Furthermore, $a_i\in I$ for all $i$ implies $a\equiv1\pmod I$.

If $I\subseteq\rad(A)$, then $a\equiv1\pmod{\rad(A)}$ implies that $a$ is a unit of $A$, so $M=a^{-1}(aM)=0$. $\qed$

Proving that a module is equal to zero might not seem impressive at first sight, but many important properties in module theory can be rephrased in these terms. For instance, a submodule $N\subseteq M$ is equal to the whole module if and only if $M/N=0$; a module homomorphism is injective if and only if its kernel is zero, and surjective if and only if its cokernel is zero; and so on. We will see some examples of this in the next section.

We can restate Nakayama's lemma as follows.

__Corollary__: Let $M$ be a finite $A$-module, and let $I\subseteq A$ be an ideal such that $M=IM$. Then there exists $b\in I$ such that $bm=m$ for all $m\in M$.

__Proof__: Let $a$ be as in Nakayama's lemma, and take $b=1-a$. $\qed$

In other words, if $M=IM$ then some element of $I$ is an obvious witness, by acting as identity on $M$.

The most important applications of Nakayama's lemma are to local rings:

__Corollary__: Let $(A,\mf m,k)$ be a local ring, and $M$ be a finite $A$-module. If $M/\mf mM=0$, then $M=0$. $\qed$

Hence the problem of showing that the $A$-module $M$ is zero is reduced to showing that the $k$-vector space $M/\mf mM$ is zero, for which we have the well-developed tools of linear algebra at our disposal.

## Applications of Nakayama's lemma

__Proposition__: Let $M$ be an $A$-module, and $N\subseteq M$ an $A$-submodule such that $M/N$ is finite over $A$. If $I\subseteq\rad(A)$ is an ideal of $A$ such that $M=N+IM$, then $M=N$.

__Proof__: Let $\overline M=M/N$. Then the given condition is equivalent to $\overline M=I\overline M$, so Nakayama's lemma gives $\overline M=0$, ie. $M=N$. $\qed$

A __minimal basis__ of an $A$-module $M$ is a set $W\subseteq M$ which generates $M$, such that no proper subset of $W$ generates $M$; in other words, a minimal generating set.

For vector spaces, the notions of minimal generating sets and maximal linearly independent sets are equivalent, but this is not true for arbitrary modules. For instance, viewing $\bb Q$ as a $\bb Z$-module, no finite subset is generating, so any minimal basis is infinite; but no two elements are $\bb Z$-linearly independent, so maximal linearly independent sets have only one element!

Also, note that two minimal bases need not have the same number of elements; for instance, if $M=A$, and $(x),(y)$ are two coprime ideals, then $\\{1\\}$ and $\\{x,y\\}$ are both minimal bases of $A$.

However, for local rings we have the following result:

__Proposition__: Let $(A,\mf m,k)$ be a local ring, and $M$ be a finite $A$-module. Let $\overline M=M/\mf mM$, which is a $k$-vector space, and let $n=\dim_k\overline M$.
1. For any basis $\\{\overline u_1,\ldots,\overline u_n\\}$ of $\overline M$ over $k$, choose inverse images $u_i\in M$ for each $\overline u_i$. Then $\\{u_1,\ldots,u_n\\}$ is a minimal basis of $M$.
2. Conversely, for every minimal basis $\\{u_1,\ldots,u_{n'}\\}$, the images $\\{\overline u_1,\ldots,\overline u_{n'}\\}$ form a basis of $\overline M$. Hence $n'=n$, ie. every minimal basis has $n$ elements.
3. If $\\{u_1,\ldots,u_n\\}$ and $\\{v_1,\ldots,v_n\\}$ are two minimal bases of $M$, and $v_i=\sum_ja_{ij}u_j$ with $a_{ij}\in A$, then $\det(a_{ij})$ is a unit of $A$, so $(a_{ij})$ is an invertible matrix.

__Proof__: (1) Note that $M=\sum Au_i+\mf mM$, and $M$ is finite implies $M/\sum Au_i$ is finite. Hence by the previous proposition, $M=\sum Au_i$.

Now if $\\{u_1,\ldots,u_n\\}$ is not minimal, say $\\{u_1,\ldots,u_{n-1}\\}$ generates $M$, then $\\{\overline u_1,\ldots,\overline u_{n-1}\\}$ generates $\overline M$, contradiction. Hence $\\{u_1,\ldots,u_n\\}$ is a minimal basis of $M$.

(2) Since $\\{u_1,\ldots,u_{n'}\\}$ generates $M$, we have $\\{\overline u_1,\ldots,\overline u_{n'}\\}$ generates $\overline M$.

Now if there is a linear relation among $\\{\overline u_1,\ldots,\overline u_{n'}\\}$, then some proper subset generates $\overline M$; by (1), this corresponds to a proper subset of $\\{u_1,\ldots,u_{n'}\\}$ which generates $M$, contradiction. Hence $\\{\overline u_1,\ldots,\overline u_{n'}\\}$ is linearly independent, so it is a basis of $\overline M$.

(3) Let $\overline a_{ij}$ be the image of $a_{ij}$ in $k=A/\mf m$, so $\overline v_i=\sum\overline a_{ij}\overline u_j$. Now $(\overline a_{ij})$ represents a change of basis over $\overline M$, so

$$0\neq\det(\overline a_{ij})=\det(a_{ij})\pmod{\mf m},$$

so $\det(a_{ij})$ is a unit of $A$. Then the inverse of $(a_{ij})$ is given by Cramer's formula. $\qed$

__Proposition__: Let $M$ be a finite $A$-module. If $f:M\to M$ is a surjective $A$-linear map, then $f$ is also injective (so it is an automorphism of $M$).

__Proof__: We will need the universal property of $A[X]$ over noncommutative rings: if $R$ is a (not necessarily commutative) ring, $\varphi:A\to R$ is a ring homomorphism, and $r\in R$ is an element commuting with every $\varphi(a)$, then there exists a ring homomorphism $\tilde\varphi:A[X]\to R$ extending $\varphi$ and sending $X$ to $r$.

Now take $R=\End(M)$, $\varphi:A\to\End(M)$ the structure homomorphism defining the $A$-module structure on $M$, and $r=f$. Then the lift $\tilde\varphi:A[X]\to\End(M)$ defines an $A[X]$-module structure on $M$, where $X\cdot m=f(m)$.

By assumption, we have $XM=M$, ie. $(X)M=M$, so by Nakayama's lemma there exists $XP(X)\in(X)$ acting as identity on $M$. Hence $\tilde\varphi(P(X))\in\End(M)$ is an inverse of $f$, so $f$ is injective. $\qed$